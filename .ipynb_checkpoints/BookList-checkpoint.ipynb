{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests import get\n",
    "\n",
    "#Sometimes not including the header results in a failed response\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "         'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "         'Referer': 'https://cssspritegenerator.com',\n",
    "         'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "         'Accept-Encoding': 'none',\n",
    "         'Accept-Language': 'en-US,en;q=0.8'}\n",
    "\n",
    "BASE_URL='https://www.goodreads.com'\n",
    "LIST_URL='https://www.goodreads.com/list/show/1.Best_Books_Ever'\n",
    "#LIST_URL='https://www.goodreads.com/list/best_of_year/2018?id=119307.Best_books_of_2018'\n",
    "\n",
    "books={'URL':[]}\n",
    "\n",
    "#the no. of pages this list has\n",
    "num_pages=5\n",
    "\n",
    "for i in range(1, num_pages):\n",
    "  time.sleep(120) #make sure you give enough time between page loads to avoid server overload\n",
    "  print(f'Reading page {i}')\n",
    "  list_page_url=f'{LIST_URL}&page={i}'\n",
    "  list_page=get(list_page_url, headers=hdr)\n",
    "  list_soup = BeautifulSoup(list_page.content, 'html.parser')\n",
    "  book_table=list_soup.find('table', attrs={'class':'tableList js-dataTooltip'})\n",
    "  rows=book_table.find_all('tr')\n",
    "  books['URL']+=[BASE_URL+r.find('a', attrs={'class':'bookTitle'}).attrs['href'] for r in rows]\n",
    "\n",
    "books_df=pd.DataFrame.from_dict(books)\n",
    "books_df.to_csv('books.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Twilight\n",
      "5 The Book Thief\n",
      "6 The Chronicles of Narnia\n",
      "7 Animal Farm\n",
      "8 J.R.R. Tolkien 4-Book Boxed Set: The Hobbit and The Lord of the Rings\n",
      "9 Gone with the Wind\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from requests import get\n",
    "\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "         'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "         'Referer': 'https://cssspritegenerator.com',\n",
    "         'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "         'Accept-Encoding': 'none',\n",
    "         'Accept-Language': 'en-US,en;q=0.8'}\n",
    "\n",
    "if not os.path.exists('book_data.csv'):\n",
    "  book_data=pd.DataFrame(columns=[\n",
    "    'image_url',\n",
    "    'book_title',\n",
    "    'book_authors',\n",
    "    'book_rating',\n",
    "    'book_rating_count',\n",
    "    'book_review_count',\n",
    "    'book_desc',\n",
    "    'book_format',\n",
    "    'book_edition',\n",
    "    'book_pages',\n",
    "    'book_isbn',\n",
    "    'genres'\n",
    "  ])\n",
    "\n",
    "  book_data.to_csv('book_data.csv')\n",
    "\n",
    "books=pd.read_csv('books.csv')\n",
    "book_data=pd.read_csv('book_data.csv')\n",
    "\n",
    "book_rows=[]\n",
    "save_every=10\n",
    "\n",
    "for i in range(len(book_data), 10):\n",
    "    time.sleep(60)\n",
    "    try:\n",
    "        book_URL=books.at[i, 'URL']\n",
    "        book_page=get(book_URL)\n",
    "        book_soup=BeautifulSoup(book_page.content, 'html.parser')\n",
    "\n",
    "        book=dict()\n",
    "\n",
    "        #Save the URL of the image of the book cover to be downloaded later\n",
    "        image_url=book_soup.find('img', attrs={'id':'coverImage'})\n",
    "        if image_url:\n",
    "            book['image_url']=image_url.attrs['src']\n",
    "        else:\n",
    "            book['image_url']=''\n",
    "\n",
    "        #Title of the book\n",
    "        book_title=book_soup.find('h1', attrs={'id':'bookTitle'})\n",
    "        if book_title:\n",
    "            book['book_title']=book_title.text.replace('\\n','').strip()\n",
    "        else:\n",
    "            book['book_title']=''\n",
    "        \n",
    "        print(i, book['book_title'])\n",
    "\n",
    "        #Author(s) of the book\n",
    "        book['book_authors']='|'.join([a.find('span', attrs={'itemprop':'name'}).text for a in book_soup.find_all('a', attrs={'class':'authorName'})])\n",
    "        \n",
    "        #Rating given by users on goodreads\n",
    "        book_rating=book_soup.find('span', attrs={'itemprop':'ratingValue'})\n",
    "        if book_rating:\n",
    "            book['book_rating']=book_rating.text.replace('\\n','').strip()\n",
    "        else:\n",
    "            book['book_rating']=''\n",
    "        book['book_rating_count']=book_soup.find('meta', attrs={'itemprop':'ratingCount'})['content']\n",
    "\n",
    "        #No. of reviews for the book\n",
    "        book['book_review_count']=book_soup.find('meta', attrs={'itemprop':'reviewCount'})['content']\n",
    "\n",
    "        #A short description of the book, usually found on the back or inside cover of the book. Also called a blurb\n",
    "        book_desc=book_soup.find('div', attrs={'class':'readable stacked'})\n",
    "        if book_desc:\n",
    "            book['book_desc']=book_desc.find_all('span')[-1].text\n",
    "        else:\n",
    "            book['book_desc']=''\n",
    "\n",
    "        #Format of the book, e.g, paperback, hardcover, Kindle edition, etc.\n",
    "        book_format=book_soup.find('div', attrs={'id':'details'}).find('span', attrs={'itemprop':'bookFormat'})\n",
    "        if book_format:\n",
    "            book['book_format']=book_format.text\n",
    "        else:\n",
    "            book['book_format']=''\n",
    "        \n",
    "        #Edition of the book\n",
    "        book_edition=book_soup.find('div', attrs={'id':'details'}).find('span', attrs={'itemprop':'bookEdition'})\n",
    "        if book_edition:\n",
    "            book['book_edition']=book_edition.text\n",
    "        else:\n",
    "            book['book_edition']=''\n",
    "\n",
    "        #No. of pages in the book\n",
    "        book_pages=book_soup.find('div', attrs={'id':'details'}).find('span', attrs={'itemprop':'numberOfPages'})\n",
    "        if book_pages:\n",
    "            book['book_pages']=book_pages.text\n",
    "        else:\n",
    "            book['book_pages']=''\n",
    "        \n",
    "        #ISBN code of the book\n",
    "        book_isbn=book_soup.find('div', attrs={'id':'bookDataBox'}).find('span', attrs={'itemprop':'isbn'})\n",
    "        if book_isbn:\n",
    "            book['book_isbn']=book_isbn.text\n",
    "        else:\n",
    "            book['book_isbn']=''\n",
    "\n",
    "        #List of genres that the book belongs to. User supplied data.\n",
    "        genres_list=book_soup.find_all('a', attrs={'class':'actionLinkLite bookPageGenreLink'})\n",
    "        book['genres']='|'.join([i.text for i in genres_list])\n",
    "        book_rows.append(book)\n",
    "\n",
    "        if i%save_every==0:\n",
    "            book_data.append(pd.DataFrame.from_dict(book_rows)).to_csv('book_data.csv', index=False)\n",
    "            book_rows=[]\n",
    "    except:\n",
    "        book_data.append(pd.DataFrame.from_dict(book_rows)).to_csv('book_data.csv', index=False)\n",
    "        book_rows=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                book_authors  \\\n",
      "0         NaN             Suzanne Collins   \n",
      "1         NaN  J.K. Rowling|Mary GrandPr√©   \n",
      "2         NaN                  Harper Lee   \n",
      "3         NaN   Jane Austen|Anna Quindlen   \n",
      "\n",
      "                                           book_desc  \\\n",
      "0  Could you survive on your own, in the wild, wi...   \n",
      "1  There is a door at the end of a silent corrido...   \n",
      "2  The unforgettable novel of a childhood in a sl...   \n",
      "3  Alternate cover edition of ISBN 9780679783268S...   \n",
      "\n",
      "                                        book_edition book_format  \\\n",
      "0                                      First Edition   Hardcover   \n",
      "1  First Scholastica trade paperback printing (US...   Paperback   \n",
      "2                                                NaN   Paperback   \n",
      "3                 Modern Library Classics, USA / CAN   Paperback   \n",
      "\n",
      "      book_isbn book_pages  book_rating  book_rating_count  book_review_count  \\\n",
      "0  9.780439e+12  374 pages         4.33            5654227             161793   \n",
      "1  9.780439e+12  870 pages         4.48            2110768              34829   \n",
      "2           NaN  324 pages         4.27            3856281              81864   \n",
      "3           NaN  279 pages         4.25            2528678              56084   \n",
      "\n",
      "                                  book_title  \\\n",
      "0                           The Hunger Games   \n",
      "1  Harry Potter and the Order of the Phoenix   \n",
      "2                      To Kill a Mockingbird   \n",
      "3                        Pride and Prejudice   \n",
      "\n",
      "                                              genres  \\\n",
      "0  Young Adult|Fiction|Science Fiction|Dystopia|F...   \n",
      "1                        Fantasy|Young Adult|Fiction   \n",
      "2  Classics|Fiction|Historical|Historical Fiction...   \n",
      "3                           Classics|Fiction|Romance   \n",
      "\n",
      "                                           image_url  \n",
      "0  https://images.gr-assets.com/books/1447303603l...  \n",
      "1  https://images.gr-assets.com/books/1546910265l...  \n",
      "2  https://images.gr-assets.com/books/1552035043l...  \n",
      "3  https://images.gr-assets.com/books/1320399351l...  \n"
     ]
    }
   ],
   "source": [
    "print(book_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..............................................................................] 39630 / 39630"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-cfad6d010ed5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbook_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'image_url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'{i}.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2269\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2270\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2272\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   2759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2760\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2761\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2762\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wget\n",
    "import os\n",
    "\n",
    "book_data=pd.read_csv('book_data.csv')\n",
    "PATH='C:\\\\Users\\\\mawad\\\\images\\\\'\n",
    "files=os.listdir(PATH)\n",
    "n=0\n",
    "if len(files)>0:\n",
    "    n=max([int(f[:-4]) for f in os.listdir(PATH)])+1\n",
    "\n",
    "for i in range(n, 5):\n",
    "    url=book_data.at[i, 'image_url']\n",
    "    filename=f'{i}.jpg'\n",
    "    if not pd.isna(url):\n",
    "        wget.download(url, PATH+filename)\n",
    "    if i%100==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'book_data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-56255feadd9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgenre_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbook_data_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbook_data_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'genres'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'book_data_train' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "genre_counts=defaultdict(int)\n",
    "for i in book_data_train.index:\n",
    "    g=book_data_train.at[i, 'genres']\n",
    "    if type(g)==str:\n",
    "        for j in g.split('|'):\n",
    "            genre_counts[j]+=1\n",
    "\n",
    "print(len(genre_counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langdetect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-e9e8d62436c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangdetect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdetect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mremove_invalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     '''\n\u001b[0;32m      4\u001b[0m     \u001b[0mRemoves\u001b[0m \u001b[0mrecords\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mhave\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mdescriptions\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mInput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langdetect'"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "def remove_invalid(df):\n",
    "    '''\n",
    "    Removes records that have invalid descriptions from the dataframe\n",
    "    Input: dataframe\n",
    "    Output: Cleaned up dataframe\n",
    "    '''\n",
    "    invalid_desc_idxs=[]\n",
    "    for i in df.index:\n",
    "        try:\n",
    "            a=detect(df.at[i,'book_desc'])\n",
    "        except:\n",
    "            invalid_desc_idxs.append(i)\n",
    "    \n",
    "    df=df.drop(index=invalid_desc_idxs)\n",
    "    return df\n",
    "\n",
    "book_data_train=remove_invalid(book_data)\n",
    "book_data_train['lang']=book_data_train.book_desc.apply(detect)\n",
    "\n",
    "#Downloading the list of languages to map the two-letter lang code to the language name\n",
    "lang_lookup=pd.read_html('https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes')[1]\n",
    "lang_lookup.drop(columns=[0], inplace=True)\n",
    "lang_lookup.columns=lang_lookup.iloc[0]\n",
    "lang_lookup=lang_lookup.reindex(lang_lookup.index.drop(0))\n",
    "lang_lookup.rename(columns={'639-1': 'lang'}, inplace=True)\n",
    "\n",
    "def get_language(lang):\n",
    "    if lang in list(lang_lookup['lang']):\n",
    "        return lang_lookup[lang_lookup['lang']==lang]['ISO language name'].values[0]\n",
    "    else:\n",
    "        return 'N/A'\n",
    "\n",
    "book_data_train['language']=book_data_train['lang'].apply(get_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
